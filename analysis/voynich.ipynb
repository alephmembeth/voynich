{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e87e2c5",
   "metadata": {},
   "source": [
    "# Glyph Frequencies and Word Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9286a6e1",
   "metadata": {},
   "source": [
    "## Letter Frequencies and Word Count in Takahashi’s transliteration (Table 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "003c9bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      37919\n",
      "o     25468\n",
      "e     20070\n",
      "h     17856\n",
      "y     17655\n",
      "a     14281\n",
      "c     13314\n",
      "d     12973\n",
      "i     11660\n",
      "l     10518\n",
      "k      9996\n",
      "r      7456\n",
      "n      6141\n",
      "t      5968\n",
      "q      5423\n",
      "\\n     5212\n",
      "S      4501\n",
      "s      2886\n",
      "p      1406\n",
      "m      1116\n",
      "T       976\n",
      "K       938\n",
      "f       425\n",
      "*       280\n",
      "P       224\n",
      "g        96\n",
      "F        80\n",
      "I        72\n",
      "x        35\n",
      "v         9\n",
      "z         2\n",
      "dtype: int64 234956\n",
      "total words: 37919\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('takahashi_clean.txt') as voy:\n",
    "    data = voy.read()\n",
    "\n",
    "print(pd.Series(list(data)).value_counts(),\n",
    "    len(data))\n",
    "\n",
    "print('total words: ' + str(len(data.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523ce60",
   "metadata": {},
   "source": [
    "# Glyph frequencies in Takahashi’s transliteration for several c combinations (Table 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8180bb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch 11008\n",
      "sh 4501\n",
      "cth 950\n",
      "ckh 906\n",
      "cph 216\n",
      "cfh 74\n",
      "c 143\n",
      "co 9\n",
      "cy 7\n",
      "cxo 0\n",
      "cxy 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17814"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern_ch  = '(ch)'\n",
    "pattern_sh  = '(Sh)'\n",
    "pattern_cth = '(cTh)'\n",
    "pattern_ckh = '(cKh)'\n",
    "pattern_cph = '(cPh)'\n",
    "pattern_cfh = '(cFh)'\n",
    "pattern_c   = '(c)+[^hTKPFoy]'\n",
    "pattern_co  = '(co)'\n",
    "pattern_cy  = '(cy)'\n",
    "pattern_cxo = '(c)+(T|K|P|F)+(o)'\n",
    "pattern_cxy = '(c)+(T|K|P|F)+(y)'\n",
    "\n",
    "matches_ch  = re.findall(pattern_ch, data)\n",
    "matches_sh  = re.findall(pattern_sh, data)\n",
    "matches_cth = re.findall(pattern_cth, data)\n",
    "matches_ckh = re.findall(pattern_ckh, data)\n",
    "matches_cph = re.findall(pattern_cph, data)\n",
    "matches_cfh = re.findall(pattern_cfh, data)\n",
    "matches_c   = re.findall(pattern_c, data)\n",
    "matches_co  = re.findall(pattern_co, data)\n",
    "matches_cy  = re.findall(pattern_cy, data)\n",
    "matches_cxo = re.findall(pattern_cxo, data)\n",
    "matches_cxy = re.findall(pattern_cxy, data)\n",
    "\n",
    "print('ch '  + str(len(matches_ch)))\n",
    "print('sh '  + str(len(matches_sh)))\n",
    "print('cth ' + str(len(matches_cth)))\n",
    "print('ckh ' + str(len(matches_ckh)))\n",
    "print('cph ' + str(len(matches_cph)))\n",
    "print('cfh ' + str(len(matches_cfh)))\n",
    "print('c '   + str(len(matches_c)))\n",
    "print('co '  + str(len(matches_co)))\n",
    "print('cy '  + str(len(matches_cy)))\n",
    "print('cxo ' + str(len(matches_cxo)))\n",
    "print('cxy ' + str(len(matches_cxy)))\n",
    "\n",
    "len(matches_ch) + len(matches_sh) + len(matches_cth) + len(matches_ckh) + len(matches_cph) + len(matches_cfh) + len(matches_c) + len(matches_co) + len(matches_cy) + len(matches_cxo) + len(matches_cxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de10d1",
   "metadata": {},
   "source": [
    "## Glyph frequencies in Takahashi’s transliteration for several i combinations (Table 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1744e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 590\n",
      "ii 195\n",
      "iii 10\n",
      "iiii 0\n",
      "n 148\n",
      "in 1752\n",
      "iin 4076\n",
      "iiin 154\n",
      "iiiin 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6927"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_i     = '([^i]+(i))+[^in]'\n",
    "pattern_ii    = '([^i]+(ii))+[^in]'\n",
    "pattern_iii   = '([^i]+(iii))+[^in]'\n",
    "pattern_iiii  = '([^i]+(iiii))+[^in]'\n",
    "pattern_n     = '[^i]+(n)'\n",
    "pattern_in    = '[^i]+(in)'\n",
    "pattern_iin   = '[^i]+(iin)'\n",
    "pattern_iiin  = '[^i]+(iiin)'\n",
    "pattern_iiiin = '[^i]+(iiiin)'\n",
    "\n",
    "matches_i     = re.findall(pattern_i, data)\n",
    "matches_ii    = re.findall(pattern_ii, data)\n",
    "matches_iii   = re.findall(pattern_iii, data)\n",
    "matches_iiii  = re.findall(pattern_iiii, data)\n",
    "matches_n     = re.findall(pattern_n, data)\n",
    "matches_in    = re.findall(pattern_in, data)\n",
    "matches_iin   = re.findall(pattern_iin, data)\n",
    "matches_iiin  = re.findall(pattern_iiin, data)\n",
    "matches_iiiin = re.findall(pattern_iiiin, data)\n",
    "\n",
    "print('i '     + str(len(matches_i)))\n",
    "print('ii '    + str(len(matches_ii)))\n",
    "print('iii '   + str(len(matches_iii)))\n",
    "print('iiii '  + str(len(matches_iiii)))\n",
    "print('n '     + str(len(matches_n)))\n",
    "print('in '    + str(len(matches_in)))\n",
    "print('iin '   + str(len(matches_iin)))\n",
    "print('iiin '  + str(len(matches_iiin)))\n",
    "print('iiiin ' + str(len(matches_iiiin)))\n",
    "\n",
    "len(matches_i) + len(matches_ii) + len(matches_iii) + len(matches_iiii) + len(matches_n) + len(matches_in) + len(matches_iin) + len(matches_iiin) + len(matches_iiiin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e64e43",
   "metadata": {},
   "source": [
    "## Glyph frequencies in Takahashi’s transliteration (Table 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4412100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh 4501\n",
      "ch 13154\n",
      "t 6944\n",
      "k 10934\n",
      "p 1630\n",
      "f 505\n",
      "i 1168\n",
      "in 1752\n",
      "iin 4232\n"
     ]
    }
   ],
   "source": [
    "pattern_t = '(t)|(T)'\n",
    "pattern_k = '(k)|(K)'\n",
    "pattern_p = '(p)|(P)'\n",
    "pattern_f = '(f)|(F)'\n",
    "\n",
    "matches_t = re.findall(pattern_t, data)\n",
    "matches_k = re.findall(pattern_k, data)\n",
    "matches_p = re.findall(pattern_p, data)\n",
    "matches_f = re.findall(pattern_f, data)\n",
    "\n",
    "print('sh '  + str(len(matches_sh)))\n",
    "print('ch '  + str(len(matches_ch) + len(matches_cth) + len(matches_ckh) + len(matches_cph) + len(matches_cfh)))\n",
    "print('t '   + str(len(matches_t)))\n",
    "print('k '   + str(len(matches_k)))\n",
    "print('p '   + str(len(matches_p)))\n",
    "print('f '   + str(len(matches_f)))\n",
    "print('i '   + str(len(matches_i) + 2 * len(matches_ii) + 3 * len(matches_iii) + 4 * len(matches_iiii) + len(matches_iiin) + 2 * len(matches_iiiin)))\n",
    "print('in '  + str(len(matches_in)))\n",
    "print('iin ' + str(len(matches_iin) + len(matches_iiin) + len(matches_iiiin)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c1b88a",
   "metadata": {},
   "source": [
    "# Entropy (Table 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f4708",
   "metadata": {},
   "source": [
    "## Entropy for Takahashi’s transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f4a4983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.021349339992516\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "def estimate_shannon_entropy(data):\n",
    "    m = len(data)\n",
    "    bases = collections.Counter([tmp_base for tmp_base in data])\n",
    "\n",
    "    shannon_entropy_value = 0\n",
    "    for base in bases:\n",
    "        n_i = bases[base]\n",
    "        p_i = n_i / float(m)\n",
    "        entropy_i = p_i * (math.log(p_i, 2))\n",
    "        shannon_entropy_value += entropy_i\n",
    "\n",
    "    return shannon_entropy_value * -1\n",
    "\n",
    "print(estimate_shannon_entropy(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a8706",
   "metadata": {},
   "source": [
    "## Entropy for the converted transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d07da84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      37919\n",
      "o     25468\n",
      "e     20070\n",
      "y     17655\n",
      "a     14281\n",
      "2     13154\n",
      "d     12973\n",
      "k     10904\n",
      "l     10518\n",
      "r      7456\n",
      "t      6918\n",
      "q      5423\n",
      "\\n     5212\n",
      "1      4501\n",
      "3      4232\n",
      "s      2886\n",
      "4      1752\n",
      "p      1622\n",
      "i      1516\n",
      "m      1116\n",
      "f       499\n",
      "*       280\n",
      "h       201\n",
      "c       160\n",
      "n       157\n",
      "g        96\n",
      "x        35\n",
      "K        32\n",
      "T        26\n",
      "v         9\n",
      "P         8\n",
      "F         6\n",
      "dtype: int64 207085\n",
      "3.8664432973586886\n"
     ]
    }
   ],
   "source": [
    "data_new = data.replace(\"Sh\", \"1\").replace(\"ch\", \"2\").replace(\"cTh\", \"2t\").replace(\"cKh\", \"2k\").replace(\"cPh\", \"2p\").replace(\"cFh\", \"2f\").replace(\"z\", \"k\").replace(\"iin\", \"3\").replace(\"in\", \"4\").replace(\"I\", \"i\")\n",
    "\n",
    "print(pd.Series(list(data_new)).value_counts(),\n",
    "    len(data_new))\n",
    "\n",
    "def estimate_shannon_entropy(data_new):\n",
    "    m = len(data_new)\n",
    "    bases = collections.Counter([tmp_base for tmp_base in data_new])\n",
    "\n",
    "    shannon_entropy_value = 0\n",
    "    for base in bases:\n",
    "        n_i = bases[base]\n",
    "        p_i = n_i / float(m)\n",
    "        entropy_i = p_i * (math.log(p_i, 2))\n",
    "        shannon_entropy_value += entropy_i\n",
    "\n",
    "    return shannon_entropy_value * -1\n",
    "\n",
    "print(estimate_shannon_entropy(data_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5376be2",
   "metadata": {},
   "source": [
    "## Entropy for a random string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a577d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o    10901\n",
      "m    10842\n",
      "i    10778\n",
      "n    10778\n",
      "r    10763\n",
      "e    10748\n",
      "h    10742\n",
      "s    10739\n",
      "d    10710\n",
      "u    10690\n",
      "p    10688\n",
      "f    10677\n",
      "k    10666\n",
      "c    10655\n",
      "g    10645\n",
      "l    10638\n",
      "a    10609\n",
      "v    10597\n",
      "t    10567\n",
      "q    10552\n",
      "b    10518\n",
      "j    10453\n",
      "dtype: int64 234956\n",
      "4.459363503358211\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "letters = 'abcdefghijklmnopqrstuv'\n",
    "\n",
    "def random_characters(length):\n",
    "    return ''.join([random.choice(letters) for x in range(0,length)])\n",
    "\n",
    "data_rand = random_characters(234956)\n",
    "\n",
    "print(pd.Series(list(data_rand)).value_counts(),\n",
    "    len(data_rand))\n",
    "\n",
    "def estimate_shannon_entropy(data_rand):\n",
    "    m = len(data_rand)\n",
    "    bases = collections.Counter([tmp_base for tmp_base in data_rand])\n",
    "\n",
    "    shannon_entropy_value = 0\n",
    "    for base in bases:\n",
    "        n_i = bases[base]\n",
    "        p_i = n_i / float(m)\n",
    "        entropy_i = p_i * (math.log(p_i, 2))\n",
    "        shannon_entropy_value += entropy_i\n",
    "\n",
    "    return shannon_entropy_value * -1\n",
    "\n",
    "print(estimate_shannon_entropy(data_rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec12387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
